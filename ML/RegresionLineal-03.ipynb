{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071db74b-ad9b-4bf9-a972-296996f7a650",
   "metadata": {},
   "source": [
    "# Regresión Lineal (03)\n",
    "\n",
    "La regresión lineal es uno de los primeros ejemplos y ejercicios a realizar al momento de introducirse en el uso del aprendizaje automático y la ciencia de datos. Es una de las formas más simples y sencillas tanto para hacer un modelo formal sobre un conjunto de datos para su anállisis y pronóstico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd76a0-b92a-4a43-b0e7-c07540e9560b",
   "metadata": {},
   "source": [
    "La regresión lineal es un caso particular de regresión polinómica, donde el grado del polinomio en la hipótesis es 1. La regresión polinómica general se analiza más adelante. Como sugiere el nombre, \"lineal\" significa que la hipótesis sobre el algoritmo de aprendizaje automático es simplemente una ecuación lineal. En la regresión lineal univariada, hay una única característica o variable de la que depende la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41642a44-636b-4403-9840-21444d4911e3",
   "metadata": {},
   "source": [
    "La hipótesis para una regresión lineal univariada es:\n",
    "\n",
    "$$ h(x) = θ_{0} + θ_{1}x $$\n",
    "\n",
    "que puede ser escrita en notación matricial o de álgebra vectorial como:\n",
    "\n",
    "$$ h(x) = \n",
    "\\begin{bmatrix}\n",
    "θ_{0}&θ_{1}\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ x\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "donde $ \\theta_{1} $ y $ \\theta_{2} $ son las dos características de las que dependerá la hipótesis, siendo una de ellas la que determina la pendiente (_slope_) de la recta y otra su intercepción (_bias_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7a512-9afe-48e7-b27f-192fbfaaf260",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "1. Navoneel Chakrabarty, \"_Implementation of Uni-Variate Polynomial Regression in Python using Gradient Descent Optimization from scratch_\", **towardsdatascience.com**, web. Published: 2018.12.19; visited: 2024.02.25. URL: [https://towardsdatascience.com/implementation-of-uni-variate-linear-regression-in-python-using-gradient-descent-optimization-from-3491a13ca2b0](https://towardsdatascience.com/implementation-of-uni-variate-linear-regression-in-python-using-gradient-descent-optimization-from-3491a13ca2b0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e1546-ca59-42a4-9356-61ea153690e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
